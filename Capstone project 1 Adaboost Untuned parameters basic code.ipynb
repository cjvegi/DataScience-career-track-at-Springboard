{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porto Seguro’s Safe Driver Prediction\n",
    "\n",
    "Porto Seguro, one of Brazil’s largest auto and homeowner insurance companies, completely agrees. Inaccuracies in car insurance company’s claim predictions raise the cost of insurance for good drivers and reduce the price for bad ones.\n",
    "\n",
    "In this competition, you’re challenged to build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. While Porto Seguro has used machine learning for the past 20 years, they’re looking to Kaggle’s machine learning community to explore new, more powerful methods. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "In this competition, you will predict the probability that an auto insurance policy holder files a claim.\n",
    "In the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). In addition, feature names include the postfix bin to indicate binary features and cat to indicate categorical features. Features without these designations are either continuous or ordinal. Values of -1 indicate that the feature was missing from the observation. The target columns signifies whether or not a claim was filed for that policy holder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starters code Adaboost\n",
    "In this notebook, we are going to use a ensemble machine learning, Random Forest model to predict wheteher a driver makes an insurance claim in the next year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### LOADING DATA ####\n",
    "\n",
    "### TRAIN DATA\n",
    "train_data = pd.read_csv('train.csv', na_values='-1')\\\n",
    "                        \n",
    "## Filling the missing data NAN with median of the column\n",
    "train_data_nato_median = pd.DataFrame()\n",
    "for column in train_data.columns:\n",
    "    train_data_nato_median[column] = train_data[column].fillna(train_data[column].median())\n",
    "\n",
    "train_data = train_data_nato_median.copy()\n",
    "\n",
    "### TEST DATA\n",
    "test_data = pd.read_csv('test.csv', na_values='-1')\n",
    "## Filling the missing data NAN with mean of the column\n",
    "test_data_nato_median = pd.DataFrame()\n",
    "for column in test_data.columns:\n",
    "    test_data_nato_median[column] = test_data[column].fillna(test_data[column].median())\n",
    "    \n",
    "test_data = test_data_nato_median.copy()\n",
    "test_data_id = test_data.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Identifying Categorical data\n",
    "column_names = train_data.columns\n",
    "categorical_column = column_names[column_names.str[10] == 'c']\n",
    "\n",
    "## Changing categorical columns to category data type\n",
    "def int_to_categorical(data):\n",
    "    \"\"\" \n",
    "    changing columns to catgorical data type\n",
    "    \"\"\"\n",
    "    for column in categorical_column:\n",
    "        data[column] =  data[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps_ind_01            int64\n",
       "ps_ind_02_cat     category\n",
       "ps_ind_03            int64\n",
       "ps_ind_04_cat     category\n",
       "ps_ind_05_cat     category\n",
       "ps_ind_06_bin        int64\n",
       "ps_ind_07_bin        int64\n",
       "ps_ind_08_bin        int64\n",
       "ps_ind_09_bin        int64\n",
       "ps_ind_10_bin        int64\n",
       "ps_ind_11_bin        int64\n",
       "ps_ind_12_bin        int64\n",
       "ps_ind_13_bin        int64\n",
       "ps_ind_14            int64\n",
       "ps_ind_15            int64\n",
       "ps_ind_16_bin        int64\n",
       "ps_ind_17_bin        int64\n",
       "ps_ind_18_bin        int64\n",
       "ps_reg_01          float64\n",
       "ps_reg_02          float64\n",
       "ps_reg_03          float64\n",
       "ps_car_01_cat     category\n",
       "ps_car_02_cat     category\n",
       "ps_car_03_cat     category\n",
       "ps_car_04_cat     category\n",
       "ps_car_05_cat     category\n",
       "ps_car_06_cat     category\n",
       "ps_car_07_cat     category\n",
       "ps_car_08_cat     category\n",
       "ps_car_09_cat     category\n",
       "ps_car_10_cat     category\n",
       "ps_car_11_cat     category\n",
       "ps_car_11          float64\n",
       "ps_car_12          float64\n",
       "ps_car_13          float64\n",
       "ps_car_14          float64\n",
       "ps_car_15          float64\n",
       "ps_calc_01         float64\n",
       "ps_calc_02         float64\n",
       "ps_calc_03         float64\n",
       "ps_calc_04           int64\n",
       "ps_calc_05           int64\n",
       "ps_calc_06           int64\n",
       "ps_calc_07           int64\n",
       "ps_calc_08           int64\n",
       "ps_calc_09           int64\n",
       "ps_calc_10           int64\n",
       "ps_calc_11           int64\n",
       "ps_calc_12           int64\n",
       "ps_calc_13           int64\n",
       "ps_calc_14           int64\n",
       "ps_calc_15_bin       int64\n",
       "ps_calc_16_bin       int64\n",
       "ps_calc_17_bin       int64\n",
       "ps_calc_18_bin       int64\n",
       "ps_calc_19_bin       int64\n",
       "ps_calc_20_bin       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating list of train and test data and converting columns of interest to categorical type\n",
    "datas = [train_data,test_data]\n",
    "\n",
    "for data in datas:\n",
    "    int_to_categorical(data)\n",
    "\n",
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Decribing categorical variables\n",
    "# def decribe_Categorical(x):\n",
    "#     \"\"\" \n",
    "#     Function to decribe Categorical data\n",
    "#     \"\"\"\n",
    "#     from IPython.display import display, HTML\n",
    "#     display(HTML(x[x.columns[x.dtypes ==\"category\"]].describe().to_html))\n",
    "\n",
    "# decribe_Categorical(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FUNCTION TO CREATE DUMMIES COLUMNS FOR CATEGORICAL VARIABLES\n",
    "def creating_dummies(data):\n",
    "    \"\"\"creating dummies columns categorical varibles\n",
    "    \"\"\"\n",
    "    for column in categorical_column:\n",
    "        dummies = pd.get_dummies(data[column],prefix=column)\n",
    "        data = pd.concat([data,dummies],axis =1)\n",
    "        ## dropping the original columns ##\n",
    "        data.drop([column],axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 220)\n",
      "(892816, 218)\n"
     ]
    }
   ],
   "source": [
    "### CREATING DUMMIES FOR CATEGORICAL VARIABLES  \n",
    "for column in categorical_column:\n",
    "        dummies = pd.get_dummies(train_data[column],prefix=column)\n",
    "        train_data = pd.concat([train_data,dummies],axis =1)\n",
    "        train_data.drop([column],axis=1,inplace= True)\n",
    "\n",
    "\n",
    "for column in categorical_column:\n",
    "        dummies = pd.get_dummies(test_data[column],prefix=column)\n",
    "        test_data = pd.concat([test_data,dummies],axis =1)\n",
    "        test_data.drop([column],axis=1,inplace= True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 218)\n",
      "(595212,)\n"
     ]
    }
   ],
   "source": [
    "#Define covariates in X and dependent variable in y\n",
    "X = train_data.iloc[:,2:] ## FEATURE DATA\n",
    "y= train_data.target ### LABEL DATA\n",
    "\n",
    "### CHECKING DIMENSIONS\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### SPLITTING DATA INTO TRAIN AND TEST SETS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2,\n",
    "                                                    random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution:\n",
      "Counter({0: 458844, 1: 17325})\n",
      "\n",
      "Test label distribution:\n",
      "Counter({0: 114674, 1: 4369})\n"
     ]
    }
   ],
   "source": [
    "## Label's Distribution\n",
    "print(\"Train label distribution:\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== AdaBoost ==\n",
      "Accuracy: 0.96\n",
      "Log loss: 0.55\n"
     ]
    }
   ],
   "source": [
    "## Adaboost Machine learning model\n",
    "adaboost = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    algorithm='SAMME',\n",
    "    n_estimators=1000,\n",
    "    random_state=seed)\n",
    "\n",
    "# train classifier\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# calculate predictions\n",
    "adaboost_y_pred = adaboost.predict(X_test)\n",
    "adaboost_y_pred_prob = adaboost.predict_proba(X_test)\n",
    "\n",
    "# evaluate\n",
    "adaboost_accuracy = accuracy_score(y_test, adaboost_y_pred)\n",
    "adaboost_logloss = log_loss(y_test, adaboost_y_pred_prob)\n",
    "\n",
    "print(\"== AdaBoost ==\")\n",
    "print(\"Accuracy: {0:.2f}\".format(adaboost_accuracy))\n",
    "print(\"Log loss: {0:.2f}\".format(adaboost_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels:\n",
      "240034    0\n",
      "122822    0\n",
      "242279    0\n",
      "594193    0\n",
      "146126    0\n",
      "Name: target, dtype: int64\n",
      "\n",
      "Predicted labels:\n",
      "[0 0 0 0 0]\n",
      "\n",
      "Predicted probabilities:\n",
      "[[ 0.58466896  0.41533104]\n",
      " [ 0.583991    0.416009  ]\n",
      " [ 0.58478572  0.41521428]\n",
      " [ 0.58519744  0.41480256]\n",
      " [ 0.58364119  0.41635881]]\n"
     ]
    }
   ],
   "source": [
    "print('True labels:')\n",
    "print(y_test[:5,])\n",
    "print('\\nPredicted labels:')\n",
    "print(adaboost_y_pred[:5,])\n",
    "print('\\nPredicted probabilities:')\n",
    "print(adaboost_y_pred_prob[:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Predicition on test data ####\n",
    "y_pred_RF_prob = adaboost.predict_proba(test_data)\n",
    "pred_values= pd.DataFrame(y_pred_RF_prob)\n",
    "\n",
    "submission_simple_adaboost= pd.DataFrame()\n",
    "submission_simple_adaboost['id'] = test_data_id\n",
    "\n",
    "submission_simple_adaboost['target'] = pd.DataFrame(pred_values.iloc[:,1])\n",
    "submission_simple_adaboost = submission_simple_adaboost.set_index('id')\n",
    "\n",
    "submission_simple_adaboost.columns\n",
    "submission_simple_adaboost.head()\n",
    "## Write to CSV\n",
    "submission_simple_adaboost.to_csv(\"Simple Adaboost.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
